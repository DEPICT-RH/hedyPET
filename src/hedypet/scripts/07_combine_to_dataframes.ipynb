{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f16cd06",
   "metadata": {},
   "source": [
    "## Means, TACS, and metadata\n",
    "Notebook used to create the following pickle data files with readouts from the combined hedyPET train+validation set (n=80):\n",
    " - `readouts/metadata.csv` Participant metadata (weight, demographic-group, and more)- `readouts/acdynPSF_tacs_80.pkl.gz` PET TACs for all segmented regions\n",
    " - `readouts/acstatPSF_mean_80.pkl.gz` PET static means for all segmented regions\n",
    " - `readouts/patlak_ki_80.pkl.gz` Patlak Ki values for all segmented regions for different input functions (IFs) and number off rames\n",
    "\n",
    "Extensive metadata and original image files available at X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da236a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hedypet.utils import DERIVATIVES_ROOT, load_splits, get_time_frames_midpoint\n",
    "from hedypet.utils import get_participant_metadata, get_norm_consts\n",
    "from nifti_dynamic.utils import load_tac\n",
    "from nifti_dynamic.patlak import roi_patlak\n",
    "from parse import parse\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import os \n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb9853",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddda7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    with open(file_path,\"r\") as handle:\n",
    "        d = json.load(handle)\n",
    "    return d\n",
    "\n",
    "region_names = {\n",
    "    'ts_total' :load_json(DERIVATIVES_ROOT / \"tacs/seg-total-classes.json\"),\n",
    "    'synthseg' :load_json(DERIVATIVES_ROOT / \"tacs/seg-synthseg_classes.json\"),\n",
    "    'synthsegparc' : load_json(DERIVATIVES_ROOT / \"tacs/seg-synthseg_classes.json\"),\n",
    "    'ts_tissue' :load_json(DERIVATIVES_ROOT / \"tacs/seg-tissue-classes.json\"),\n",
    "    'ts_body' : load_json(DERIVATIVES_ROOT / \"tacs/seg-body-classes.json\"),\n",
    "    'totalimage' : {\"1\":\"body\"},\n",
    "}\n",
    "region_names_aorta = load_json(DERIVATIVES_ROOT / \"tacs/seg-aorta-classes.json\")\n",
    "\n",
    "def task_and_ix_to_region_name(task,ix):\n",
    "    if task.startswith(\"aorta\"):\n",
    "        return region_names_aorta[ix]\n",
    "    else:\n",
    "        return region_names[task][ix]\n",
    "\n",
    "subs = load_splits()[\"train0\"]+load_splits()[\"val0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59484cdf",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "Extraction of metadata for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "785ec4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(df_path := \"../../../readouts/metadata.csv\"):\n",
    "    data = []\n",
    "    for sub in load_splits()[\"train0\"]+load_splits()[\"val0\"]:\n",
    "        x = get_participant_metadata(sub)\n",
    "        x[\"suv_denominator\"] = get_norm_consts(sub)[\"suv\"]\n",
    "        data.append(x)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.rename({\"InjectedRadioactivity\":\"injected_readioactivity\"},axis=1)\n",
    "    df = df.drop([\"age\",\"height\",\"sex\",\"blanket\"],axis=1)\n",
    "    df.to_csv(df_path,index=False)\n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cfd916",
   "metadata": {},
   "source": [
    "## Time Activity Curves\n",
    "Combines the time activity curves from the acdynPSF dynamic PET into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28d952bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(df_path := \"../../../readouts/acdynPSF_tacs_80.pkl.gz\"):\n",
    "    data = []\n",
    "    \n",
    "    for sub in tqdm(subs):\n",
    "        tacs_root = (DERIVATIVES_ROOT / f\"tacs/{sub}/acdynPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "        frame_time_middle = get_time_frames_midpoint(sub)\n",
    "                \n",
    "        for tac_organ_path in tacs:\n",
    "            mu_organ, std_organ, n_organ = load_tac(tac_organ_path)\n",
    "            frame_ixs = list(range(len(mu_organ)))\n",
    "\n",
    "            assert len(frame_ixs) == len(frame_time_middle)\n",
    "            \n",
    "            tags = parse('{}/tacs/{sub}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_organ_path)).named\n",
    "            vals = {\"pet_mu\":mu_organ,\"pet_std\":std_organ,\"n_voxels\":n_organ,\"frame_ix\":frame_ixs, \"frame_time_middle\":frame_time_middle}\n",
    "            vals.update(tags)\n",
    "            vals[\"seg_region_name\"] = task_and_ix_to_region_name(vals[\"task\"],vals[\"ix\"])\n",
    "            data.append(pd.DataFrame(vals))\n",
    "\n",
    "    df = pd.concat(data)\n",
    "    df = df.rename({\"sub\":\"participant\",\"task\":\"seg_task\",\"ix\":\"seg_region_ix\",\"erosion\":\"erosion_iterations\"},axis=\"columns\")\n",
    "    df[\"mL\"] = df.n_voxels*(1.65*1.65* 1.65) / 1000\n",
    "    df.to_pickle(df_path)\n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cda002",
   "metadata": {},
   "source": [
    "## Static Organ Means\n",
    "Combines the static organ means from the acstatPSF reconstruction into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "115e5dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [01:51<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(df_path := \"../../../readouts/acstatPSF_means_80.pkl.gz\"):\n",
    "    data = []\n",
    "    \n",
    "    for sub in tqdm(subs):\n",
    "        tacs_root = (DERIVATIVES_ROOT / f\"tacs/{sub}/acstatPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "                \n",
    "        # Try all combinations of inputs functions and num_frames\n",
    "        for tac_organ_path in tacs:\n",
    "            mu_organ, std_organ, n_organ = load_tac(tac_organ_path)\n",
    "            tags = parse('{}/tacs/{sub}/acstatPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_organ_path)).named\n",
    "            vals = {\"pet_mu\":float(mu_organ),\"pet_std\":float(std_organ),\"n_voxels\":int(n_organ)}\n",
    "            vals.update(tags)\n",
    "            vals[\"seg_region_name\"] = task_and_ix_to_region_name(vals[\"task\"],vals[\"ix\"])\n",
    "            data.append(vals)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.rename({\"sub\":\"participant\",\"task\":\"seg_task\",\"ix\":\"seg_region_ix\",\"erosion\":\"erosion_iterations\"},axis=\"columns\")\n",
    "    df[\"mL\"] = df.n_voxels*(1.65*1.65* 2.0) / 1000\n",
    "    df.to_pickle(df_path)\n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba510e8",
   "metadata": {},
   "source": [
    "## Patlak\n",
    "\n",
    "Computes and saves the Patlak Ki for different organ and input-function combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6177766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 54/80 [24:34<12:45, 29.46s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not os.path.exists(df_path := \"../../../readouts/patlak_ki_80.pkl.gz\"):\n",
    "\n",
    "    frames = [2,3,4,5,6,7,8]\n",
    "    ki_data = []\n",
    "\n",
    "    for sub in tqdm(subs):\n",
    "        #Find all tacs\n",
    "        tacs_root = (DERIVATIVES_ROOT / f\"tacs/{sub}/acdynPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "\n",
    "        tacs_if = [x for x in tacs if \"aortavois\" in str(x)]\n",
    "        tacs_organs = [x for x in tacs if \"aorta\" not in str(x)]\n",
    "        \n",
    "        t_middle = get_time_frames_midpoint(sub)\n",
    "\n",
    "        # Try all combinations of inputs functions and num_frames\n",
    "        for tac_if_path in tacs_if:\n",
    "            tac_if, _, _ = load_tac(tac_if_path)\n",
    "            for tac_organ_path in tacs_organs:\n",
    "                tac_organ, _, n = load_tac(tac_organ_path)\n",
    "                for frame in frames:\n",
    "                    slope, intercept, X, Y = roi_patlak(tac_organ,tac_if,t_middle,frame)\n",
    "\n",
    "                    tags_if = parse('{}/tacs/{}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_if_path)).named\n",
    "                    tags_organ = parse('{}/tacs/{sub}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_organ_path)).named\n",
    "                    \n",
    "                    if_tag = tags_if[\"task\"]+\"_\"+task_and_ix_to_region_name(tags_if[\"task\"], tags_if[\"ix\"])\n",
    "                    \n",
    "                    series = {\"Ki\":float(slope),\"n_voxels\":int(n[0]),\"n_frames_regression\":frame}\n",
    "                    series[\"if_tag\"] = if_tag\n",
    "                    series.update(tags_organ)\n",
    "                    series[\"seg_region_name\"] = task_and_ix_to_region_name(series[\"task\"], series[\"ix\"])\n",
    "                    ki_data.append(series)\n",
    "                    \n",
    "    df = pd.DataFrame(ki_data)\n",
    "    df = df.rename({\"sub\":\"participant\",\"task\":\"seg_task\",\"ix\":\"seg_region_ix\",\"erosion\":\"erosion_iterations\"},axis=\"columns\")\n",
    "    df[\"mL\"] = df.n_voxels*(1.65*1.65* 1.65) / 1000\n",
    "    df.to_pickle(df_path)\n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829709c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: Index(['mu', 'std', 'n', 'sub', 'task', 'erosion', 'ix', 'region'], dtype='object')\n",
      "Unique task: ['ts_total' 'synthseg' 'synthsegparc' 'ts_tissue' 'ts_body' 'totalimage']\n",
      "Unique erosion: ['0' '1']\n",
      "Available normalizations: ['suv', 'sul_janma', 'sul_james', 'sul_decazes', 'suv_id', 'sul_id']\n",
      "Rows: 49751\n",
      "Subjects: 100\n"
     ]
    }
   ],
   "source": [
    "from hedypet.utils import get_norm_consts\n",
    "\n",
    "print(\"Columns:\", df.columns)\n",
    "print(\"Unique task:\", df.task.unique())\n",
    "print(\"Unique erosion:\", df.erosion.unique())\n",
    "print(\"Rows:\",len(df))\n",
    "print(\"Subjects:\", df[\"sub\"].nunique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hedyPET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
