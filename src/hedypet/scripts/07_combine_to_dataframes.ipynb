{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f16cd06",
   "metadata": {},
   "source": [
    "## Means, TACS, and metadata\n",
    "Notebook used to create the following pickle data files with readouts from the combined hedyPET train+validation set (n=80):\n",
    " - `readouts/metadata.csv` Participant metadata (weight, demographic-group, and more)- `readouts/acdynPSF_tacs_80.pkl.gz` PET TACs for all segmented regions\n",
    " - `readouts/acstatPSF_mean_80.pkl.gz` PET static means for all segmented regions\n",
    " - `readouts/patlak_ki_80.pkl.gz` Patlak Ki values for all segmented regions for different input functions (IFs) and number off rames\n",
    "\n",
    "Extensive metadata and original image files available at X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da236a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hedypet.utils import STATIC_ROOT, load_splits, get_time_frames_midpoint, DYNAMIC_ROOT\n",
    "from hedypet.utils import get_participant_metadata, get_norm_consts\n",
    "from nifti_dynamic.tacs import load_tac\n",
    "from nifti_dynamic.patlak import roi_patlak\n",
    "from parse import parse\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import os \n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb9853",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ddda7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tsv(file_path):\n",
    "    df = pd.read_csv(file_path,sep=\"\\t\")\n",
    "    return {k:v for k,v in zip(list(df[\"index\"]),list(df.name))}\n",
    "\n",
    "region_names = {\n",
    "    'ts_total' :load_tsv(next((STATIC_ROOT / \"derivatives/totalsegmentator\").glob(\"**/*total*.tsv\"))),\n",
    "    'ts_body' : load_tsv(next((STATIC_ROOT / \"derivatives/totalsegmentator\").glob(\"**/*body*.tsv\"))),\n",
    "    'ts_tissue' :load_tsv(next((STATIC_ROOT / \"derivatives/totalsegmentator\").glob(\"**/*tissue*.tsv\"))),\n",
    "    'synthsegparc' : load_tsv(next((STATIC_ROOT / \"derivatives/synthseg\").glob(\"**/*synthseg*.tsv\"))),\n",
    "    'synthseg' : load_tsv(next((STATIC_ROOT / \"derivatives/synthseg\").glob(\"**/*synthseg*.tsv\"))),\n",
    "    'totalimage' : {1:\"body\"},\n",
    "}\n",
    "\n",
    "region_names_aorta = {1:\"aorta_ascending\",\n",
    "2:\"aorta_top\",\n",
    "3:\"aorta_descending_upper\",\n",
    "4:\"aorta_descending_lower\"}\n",
    "\n",
    "def task_and_ix_to_region_name(task,ix):\n",
    "    ix = int(ix)\n",
    "    if task.startswith(\"aorta\"):\n",
    "        return region_names_aorta[ix]\n",
    "    else:\n",
    "        return region_names[task][ix]\n",
    "\n",
    "subs = load_splits()[\"train0\"]+load_splits()[\"val0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59484cdf",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "Extraction of metadata for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "785ec4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========[Metadata Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Weight [kg]', 'Demographic Group [Sex,Age]', 'suv_const', 'sul_janma_const', 'sul_james_const', 'Injected Activity [MBq]', 'SUV Denominator [Bq/mL]', 'SUL Decazes Denominator [Bq/mL]', 'SUL Janma Denominator [Bq/mL]', 'SUL James Denominator [Bq/mL]']\n",
      "\n",
      "Subjects: 80\n",
      "\n",
      "Demographic Group [Sex,Age]\n",
      "F18-34    10\n",
      "F35-49    10\n",
      "F50-69    10\n",
      "F70-99    10\n",
      "M18-34    10\n",
      "M35-49    10\n",
      "M50-69    10\n",
      "M70-99    10\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(df_path := \"../../../readouts/metadata_80.csv\"):\n",
    "    data = []\n",
    "    for sub in load_splits()[\"train0\"]+load_splits()[\"val0\"]:\n",
    "        x = get_participant_metadata(sub)\n",
    "        x[\"SUV Denominator [Bq/mL]\"] = get_norm_consts(sub)[\"suv\"]\n",
    "        x[\"SUL Decazes Denominator [Bq/mL]\"] = get_norm_consts(sub)[\"sul_decazes\"]\n",
    "        x[\"SUL Janma Denominator [Bq/mL]\"] = get_norm_consts(sub)[\"sul_janma\"]\n",
    "        x[\"SUL James Denominator [Bq/mL]\"] = get_norm_consts(sub)[\"sul_james\"]\n",
    "        data.append(x)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.rename({\"InjectedRadioactivity\":\"Injected Activity [MBq]\",\"participant_id\":\"Subject\",\"weight\":\"Weight [kg]\",\"demographic-group\":\"Demographic Group [Sex,Age]\"},axis=1)\n",
    "    df = df.drop([\"age\",\"height\",\"sex\",\"blanket\"],axis=1)\n",
    "    df.to_csv(df_path,index=False)\n",
    "else:\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "print(\"=\"*10 + \"[Metadata Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Subjects:\", df[\"Subject\"].nunique(),end=\"\\n\\n\")\n",
    "print(df[\"Demographic Group [Sex,Age]\"].value_counts(),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cfd916",
   "metadata": {},
   "source": [
    "## Time Activity Curves\n",
    "Combines the time activity curves from the acdynPSF dynamic PET into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d952bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [01:16<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========[Time Activity Curves Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Task', 'Label Index', 'Label Name', 'Erosion Iterations', 'Frame Index', 'Frame Time Middle [s]', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count', 'Volume [mL]']\n",
      "\n",
      "Segmentation tasks: ['ts_total', 'synthseg', 'synthsegparc', 'ts_tissue', 'ts_body', 'aortasegments', 'aortavois_ml-full_width-3', 'aortavois_ml-1_width-3', 'aortavois_ml-2_width-5', 'totalimage']\n",
      "\n",
      "N Unique regions: 227\n",
      "\n",
      "Unique erosions: [0 1]\n",
      "\n",
      "Rows: 2860533\n",
      "\n",
      "\n",
      "==========[Input Functions Time Activity Curves Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Task', 'Label Index', 'Label Name', 'Erosion Iterations', 'Frame Index', 'Frame Time Middle [s]', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count', 'Volume [mL]']\n",
      "\n",
      "Segmentation tasks: ['aortavois_ml-full_width-3', 'aortavois_ml-1_width-3', 'aortavois_ml-2_width-5']\n",
      "\n",
      "N Unique regions: 4\n",
      "\n",
      "Unique erosions: [0]\n",
      "\n",
      "Rows: 66240\n"
     ]
    }
   ],
   "source": [
    "df_path = \"../../../readouts/tacs_80.pkl.gz\"\n",
    "df_path_input_function = \"../../../readouts/input_function_tacs_80.pkl.gz\"\n",
    "\n",
    "if not os.path.exists(df_path) or not os.path.exists(df_path_input_function):\n",
    "    data = []\n",
    "    \n",
    "    for sub in tqdm(subs):\n",
    "        tacs_root = (DYNAMIC_ROOT / f\"derivatives/tacs/{sub}/acdynPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "\n",
    "\n",
    "        # Load the TAC for each ROI with/without erosion\n",
    "        for tac_roi_path in tacs:\n",
    "\n",
    "            frame_time_start, frame_duration,mu_organ, std_organ, n_organ = load_tac(tac_roi_path)\n",
    "            if (frame_duration==0).all():\n",
    "                frame_duration = np.array(list(frame_time_start[1:]) + [4200]) - frame_time_start\n",
    "\n",
    "            frame_time_middle = frame_time_start+frame_duration/2\n",
    "            # Save data to dataframe\n",
    "            frame_ixs = list(range(len(mu_organ)))            \n",
    "            tags = parse('{}/tacs/{sub}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}.csv',str(tac_roi_path)).named\n",
    "            vals = {\"PET Mean [Bq/mL]\":mu_organ,\"PET STD [Bq/mL]\":std_organ,\"Voxel Count\":n_organ,\"Frame Index\":frame_ixs, \"Frame Time Middle [s]\":frame_time_middle}\n",
    "            vals.update(tags)\n",
    "            vals[\"Label Name\"] = task_and_ix_to_region_name(vals[\"task\"],vals[\"ix\"])\n",
    "            data.append(pd.DataFrame(vals))\n",
    "\n",
    "    # Rename and save \n",
    "    df = pd.concat(data)\n",
    "    df = df.rename({\"sub\":\"Subject\",\"task\":\"Task\",\"ix\":\"Label Index\",\"erosion\":\"Erosion Iterations\"},axis=\"columns\")\n",
    "    df[\"Volume [mL]\"] = df[\"Voxel Count\"]*(1.65*1.65* 1.65) / 1000\n",
    "    df[\"Erosion Iterations\"] = df[\"Erosion Iterations\"].astype(int)\n",
    "    df = df[['Subject', 'Task','Label Index', 'Label Name', 'Erosion Iterations', 'Frame Index', 'Frame Time Middle [s]', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count',  'Volume [mL]']]\n",
    "    \n",
    "    df_input_functions = df[df.Task.str.startswith(\"aortavois\")]\n",
    "    df_organs = df[~df.Task.str.startswith(\"aortavois\")]\n",
    "    df_input_functions.to_pickle(df_path_input_function)\n",
    "    df_organs.to_pickle(df_path)\n",
    "else:\n",
    "    df_input_functions = pd.read_pickle(df_path_input_function)\n",
    "    df_organs = pd.read_pickle(df_path)\n",
    "\n",
    "print(\"=\"*10 + \"[Time Activity Curves Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df[\"Task\"].unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"Label Name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df[\"Erosion Iterations\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df),end=\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\"*10 + \"[Input Functions Time Activity Curves Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df_input_functions.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df_input_functions[\"Task\"].unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df_input_functions[\"Label Name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df_input_functions[\"Erosion Iterations\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df_input_functions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cda002",
   "metadata": {},
   "source": [
    "## Static Organ Means\n",
    "Combines the static organ means from the acstatPSF reconstruction into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "115e5dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [02:04<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========[Means Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Task', 'Label Index', 'Label Name', 'Erosion Iterations', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count', 'Volume [mL]']\n",
      "\n",
      "Segmentation tasks: ['ts_total', 'synthseg', 'synthsegparc', 'ts_tissue', 'ts_body', 'totalimage']\n",
      "\n",
      "N Unique regions: 223\n",
      "\n",
      "Unique erosions: [0 1]\n",
      "\n",
      "Rows: 39809\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(df_path := \"../../../readouts/means_80.pkl.gz\"):\n",
    "    data = []\n",
    "    \n",
    "    for sub in tqdm(subs):\n",
    "        tacs_root = (STATIC_ROOT / f\"derivatives/tacs/{sub}/acstatPSF\")\n",
    "\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "                \n",
    "        # Load the ROI means for all regions (with/without eerosion)\n",
    "        for tac_roi_path in tacs:\n",
    "            _,_,mu_organ, std_organ, n_organ = load_tac(tac_roi_path)\n",
    "\n",
    "            # Save data to dataframe\n",
    "            tags = parse('{}/tacs/{sub}/acstatPSF/{task}/erosion-{erosion}/tac_{ix}.csv',str(tac_roi_path)).named\n",
    "            vals = {\"PET Mean [Bq/mL]\":float(mu_organ.item()),\"PET STD [Bq/mL]\":float(std_organ.item()),\"Voxel Count\":int(n_organ.item())}\n",
    "            vals.update(tags)\n",
    "            vals[\"Label Name\"] = task_and_ix_to_region_name(vals[\"task\"],vals[\"ix\"])\n",
    "            data.append(vals)\n",
    "\n",
    "    # Rename and save \n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.rename({\"sub\":\"Subject\",\"task\":\"Task\",\"ix\":\"Label Index\",\"erosion\":\"Erosion Iterations\"},axis=\"columns\")\n",
    "    df[\"Volume [mL]\"] = df[\"Voxel Count\"]*(1.65*1.65* 2.0) / 1000\n",
    "    df[\"Erosion Iterations\"] = df[\"Erosion Iterations\"].astype(int)\n",
    "    df = df[['Subject', 'Task','Label Index', 'Label Name', 'Erosion Iterations', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count', 'Volume [mL]']]\n",
    "    df.to_pickle(df_path)\n",
    "    \n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n",
    "\n",
    "print(\"=\"*10 + \"[Means Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df[\"Task\"].unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"Label Name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df[\"Erosion Iterations\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba510e8",
   "metadata": {},
   "source": [
    "## Patlak\n",
    "\n",
    "Computes and saves the Patlak Ki for different organ and input-function combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36052701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00e+00, -2.00e+00, -4.00e+00, -6.00e+00, -8.00e+00, -1.00e+01,\n",
       "       -1.20e+01, -1.40e+01, -1.60e+01, -1.80e+01, -2.00e+01, -2.20e+01,\n",
       "       -2.40e+01, -2.60e+01, -2.80e+01, -3.00e+01, -3.20e+01, -3.40e+01,\n",
       "       -3.60e+01, -3.80e+01, -4.00e+01, -4.50e+01, -5.00e+01, -5.50e+01,\n",
       "       -6.00e+01, -6.50e+01, -7.00e+01, -7.50e+01, -8.00e+01, -8.50e+01,\n",
       "       -9.00e+01, -1.00e+02, -1.10e+02, -1.20e+02, -1.30e+02, -1.40e+02,\n",
       "       -1.50e+02, -1.60e+02, -1.70e+02, -1.80e+02, -1.90e+02, -2.00e+02,\n",
       "       -2.10e+02, -2.20e+02, -2.30e+02, -2.40e+02, -3.00e+02, -3.60e+02,\n",
       "       -4.20e+02, -4.80e+02, -5.40e+02, -6.00e+02, -7.20e+02, -8.40e+02,\n",
       "       -9.60e+02, -1.08e+03, -1.20e+03, -1.32e+03, -1.44e+03, -1.56e+03,\n",
       "       -1.68e+03, -1.80e+03, -2.10e+03, -2.40e+03, -2.70e+03, -3.00e+03,\n",
       "       -3.30e+03, -3.60e+03, -3.60e+03])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e28d713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.0e+00,  2.0e+00,  2.0e+00,  2.0e+00,  2.0e+00,  2.0e+00,\n",
       "        2.0e+00,  2.0e+00,  2.0e+00,  2.0e+00,  2.0e+00,  2.0e+00,\n",
       "        2.0e+00,  2.0e+00,  2.0e+00,  2.0e+00,  2.0e+00,  2.0e+00,\n",
       "        2.0e+00,  2.0e+00,  5.0e+00,  5.0e+00,  5.0e+00,  5.0e+00,\n",
       "        5.0e+00,  5.0e+00,  5.0e+00,  5.0e+00,  5.0e+00,  5.0e+00,\n",
       "        1.0e+01,  1.0e+01,  1.0e+01,  1.0e+01,  1.0e+01,  1.0e+01,\n",
       "        1.0e+01,  1.0e+01,  1.0e+01,  1.0e+01,  1.0e+01,  1.0e+01,\n",
       "        1.0e+01,  1.0e+01,  1.0e+01,  6.0e+01,  6.0e+01,  6.0e+01,\n",
       "        6.0e+01,  6.0e+01,  6.0e+01,  1.2e+02,  1.2e+02,  1.2e+02,\n",
       "        1.2e+02,  1.2e+02,  1.2e+02,  1.2e+02,  1.2e+02,  1.2e+02,\n",
       "        1.2e+02,  3.0e+02,  3.0e+02,  3.0e+02,  3.0e+02,  3.0e+02,\n",
       "        3.0e+02,  3.0e+02, -3.6e+03])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e279ea18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00e+00, 4.00e+00, 6.00e+00, 8.00e+00, 1.00e+01, 1.20e+01,\n",
       "       1.40e+01, 1.60e+01, 1.80e+01, 2.00e+01, 2.20e+01, 2.40e+01,\n",
       "       2.60e+01, 2.80e+01, 3.00e+01, 3.20e+01, 3.40e+01, 3.60e+01,\n",
       "       3.80e+01, 4.00e+01, 4.50e+01, 5.00e+01, 5.50e+01, 6.00e+01,\n",
       "       6.50e+01, 7.00e+01, 7.50e+01, 8.00e+01, 8.50e+01, 9.00e+01,\n",
       "       1.00e+02, 1.10e+02, 1.20e+02, 1.30e+02, 1.40e+02, 1.50e+02,\n",
       "       1.60e+02, 1.70e+02, 1.80e+02, 1.90e+02, 2.00e+02, 2.10e+02,\n",
       "       2.20e+02, 2.30e+02, 2.40e+02, 3.00e+02, 3.60e+02, 4.20e+02,\n",
       "       4.80e+02, 5.40e+02, 6.00e+02, 7.20e+02, 8.40e+02, 9.60e+02,\n",
       "       1.08e+03, 1.20e+03, 1.32e+03, 1.44e+03, 1.56e+03, 1.68e+03,\n",
       "       1.80e+03, 2.10e+03, 2.40e+03, 2.70e+03, 3.00e+03, 3.30e+03,\n",
       "       3.60e+03, 3.90e+03, 3.00e+02])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(frame_time_start[1:]) + [300]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6177766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [35:11<00:00, 26.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========[Patlak Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Task', 'Label Index', 'Label Name', 'Erosion Iterations', 'Input Function Identifier', 'Regression Frames', 'Patlak Ki', 'Voxel Count', 'Volume [mL]']\n",
      "\n",
      "Segmentation tasks: ['ts_total', 'synthseg', 'synthsegparc', 'ts_tissue', 'ts_body', 'totalimage']\n",
      "\n",
      "N Unique regions: 223\n",
      "\n",
      "Unique erosions: [0 1]\n",
      "\n",
      "Unique patlak frames: [2 3 4 5 6 7 8]\n",
      "\n",
      "Unique input functions ['aortavois_ml-full_width-3_aorta_ascending'\n",
      " 'aortavois_ml-full_width-3_aorta_top'\n",
      " 'aortavois_ml-full_width-3_aorta_descending_upper'\n",
      " 'aortavois_ml-full_width-3_aorta_descending_lower'\n",
      " 'aortavois_ml-1_width-3_aorta_ascending'\n",
      " 'aortavois_ml-1_width-3_aorta_top'\n",
      " 'aortavois_ml-1_width-3_aorta_descending_upper'\n",
      " 'aortavois_ml-1_width-3_aorta_descending_lower'\n",
      " 'aortavois_ml-2_width-5_aorta_ascending'\n",
      " 'aortavois_ml-2_width-5_aorta_top'\n",
      " 'aortavois_ml-2_width-5_aorta_descending_upper'\n",
      " 'aortavois_ml-2_width-5_aorta_descending_lower']\n",
      "\n",
      "Rows: 3347988\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np \n",
    "\n",
    "if not os.path.exists(df_path := \"../../../readouts/patlak_ki_80.pkl.gz\"):\n",
    "\n",
    "    #Number of last frames to perform Patlak regression on\n",
    "    frames = [2,3,4,5,6,7,8]\n",
    "    ki_data = []\n",
    "\n",
    "    for sub in tqdm(subs):\n",
    "\n",
    "        #Find all TACs (organs, input functions, and with/without erosion)\n",
    "        tacs_root = (DYNAMIC_ROOT / f\"derivatives/tacs/{sub}/acdynPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "\n",
    "        #Divide into input function TACs and ROI tacs\n",
    "        tacs_if = [x for x in tacs if \"aortavois\" in str(x)]\n",
    "        tacs_roi = [x for x in tacs if \"aorta\" not in str(x)]\n",
    "        \n",
    "        # For each input function\n",
    "        for tac_if_path in tacs_if:\n",
    "            frame_time_start, frame_duration,tac_if, _, _ = load_tac(tac_if_path)\n",
    "            if (frame_duration==0).all():\n",
    "                frame_duration = np.array(list(frame_time_start[1:]) + [4200]) - frame_time_start\n",
    "\n",
    "            t_middle = frame_time_start+frame_duration/2\n",
    "            # For each organ\n",
    "            for tac_roi_path in tacs_roi:\n",
    "                _,_, tac_organ, _, n = load_tac(tac_roi_path)\n",
    "            \n",
    "                # For different number of regression Frames\n",
    "                for frame in frames:\n",
    "\n",
    "                    # Run Patlak analysis\n",
    "                    slope, intercept, X, Y = roi_patlak(tac_organ,tac_if,t_middle,frame)\n",
    "\n",
    "                    # And parse the data for the dataframe\n",
    "                    tags_if = parse('{}/tacs/{}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}.csv',str(tac_if_path)).named\n",
    "                    tags_organ = parse('{}/tacs/{sub}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}.csv',str(tac_roi_path)).named\n",
    "                    if_tag = tags_if[\"task\"]+\"_\"+task_and_ix_to_region_name(tags_if[\"task\"], tags_if[\"ix\"])\n",
    "                    series = {\"Patlak Ki\":float(slope),\"Voxel Count\":int(n[0]),\"Regression Frames\":frame}\n",
    "                    series[\"Input Function Identifier\"] = if_tag\n",
    "                    series.update(tags_organ)\n",
    "                    series[\"Label Name\"] = task_and_ix_to_region_name(series[\"task\"], series[\"ix\"])\n",
    "                    \n",
    "                    ki_data.append(series)\n",
    "                    \n",
    "    # Rename and save \n",
    "    df = pd.DataFrame(ki_data)\n",
    "    df = df.rename({\"sub\":\"Subject\",\"task\":\"Task\",\"ix\":\"Label Index\",\"erosion\":\"Erosion Iterations\"},axis=\"columns\")\n",
    "    df[\"Volume [mL]\"] = df[\"Voxel Count\"]*(1.65*1.65* 1.65) / 1000\n",
    "    df[\"Erosion Iterations\"] = df[\"Erosion Iterations\"].astype(int)\n",
    "    df = df[['Subject','Task',  'Label Index', 'Label Name', 'Erosion Iterations', 'Input Function Identifier', 'Regression Frames', 'Patlak Ki', 'Voxel Count', 'Volume [mL]']]\n",
    "    df.to_pickle(df_path)\n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n",
    "\n",
    "print(\"=\"*10 + \"[Patlak Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df[\"Task\"].unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"Label Name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df[\"Erosion Iterations\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Unique patlak frames:\", df[\"Regression Frames\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Unique input functions\" , df[\"Input Function Identifier\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4470c395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00e+00, 2.00e+00, 4.00e+00, 6.00e+00, 8.00e+00, 1.00e+01,\n",
       "        1.20e+01, 1.40e+01, 1.60e+01, 1.80e+01, 2.00e+01, 2.20e+01,\n",
       "        2.40e+01, 2.60e+01, 2.80e+01, 3.00e+01, 3.20e+01, 3.40e+01,\n",
       "        3.60e+01, 3.80e+01, 4.00e+01, 4.50e+01, 5.00e+01, 5.50e+01,\n",
       "        6.00e+01, 6.50e+01, 7.00e+01, 7.50e+01, 8.00e+01, 8.50e+01,\n",
       "        9.00e+01, 1.00e+02, 1.10e+02, 1.20e+02, 1.30e+02, 1.40e+02,\n",
       "        1.50e+02, 1.60e+02, 1.70e+02, 1.80e+02, 1.90e+02, 2.00e+02,\n",
       "        2.10e+02, 2.20e+02, 2.30e+02, 2.40e+02, 3.00e+02, 3.60e+02,\n",
       "        4.20e+02, 4.80e+02, 5.40e+02, 6.00e+02, 7.20e+02, 8.40e+02,\n",
       "        9.60e+02, 1.08e+03, 1.20e+03, 1.32e+03, 1.44e+03, 1.56e+03,\n",
       "        1.68e+03, 1.80e+03, 2.10e+03, 2.40e+03, 2.70e+03, 3.00e+03,\n",
       "        3.30e+03, 3.60e+03, 3.90e+03]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_time_start, frame_time_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fc5ec52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Task</th>\n",
       "      <th>Label Index</th>\n",
       "      <th>Label Name</th>\n",
       "      <th>Erosion Iterations</th>\n",
       "      <th>Input Function Identifier</th>\n",
       "      <th>Regression Frames</th>\n",
       "      <th>Patlak Ki</th>\n",
       "      <th>Voxel Count</th>\n",
       "      <th>Volume [mL]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-072</td>\n",
       "      <td>ts_total</td>\n",
       "      <td>1</td>\n",
       "      <td>spleen</td>\n",
       "      <td>0</td>\n",
       "      <td>aortavois_ml-full_width-3_aorta_ascending</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>44072</td>\n",
       "      <td>197.976933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-072</td>\n",
       "      <td>ts_total</td>\n",
       "      <td>1</td>\n",
       "      <td>spleen</td>\n",
       "      <td>0</td>\n",
       "      <td>aortavois_ml-full_width-3_aorta_ascending</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>44072</td>\n",
       "      <td>197.976933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-072</td>\n",
       "      <td>ts_total</td>\n",
       "      <td>1</td>\n",
       "      <td>spleen</td>\n",
       "      <td>0</td>\n",
       "      <td>aortavois_ml-full_width-3_aorta_ascending</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>44072</td>\n",
       "      <td>197.976933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-072</td>\n",
       "      <td>ts_total</td>\n",
       "      <td>1</td>\n",
       "      <td>spleen</td>\n",
       "      <td>0</td>\n",
       "      <td>aortavois_ml-full_width-3_aorta_ascending</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>44072</td>\n",
       "      <td>197.976933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-072</td>\n",
       "      <td>ts_total</td>\n",
       "      <td>1</td>\n",
       "      <td>spleen</td>\n",
       "      <td>0</td>\n",
       "      <td>aortavois_ml-full_width-3_aorta_ascending</td>\n",
       "      <td>6</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>44072</td>\n",
       "      <td>197.976933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347983</th>\n",
       "      <td>sub-048</td>\n",
       "      <td>totalimage</td>\n",
       "      <td>1</td>\n",
       "      <td>body</td>\n",
       "      <td>0</td>\n",
       "      <td>aortavois_ml-2_width-5_aorta_descending_lower</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>124872000</td>\n",
       "      <td>560940.633000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347984</th>\n",
       "      <td>sub-048</td>\n",
       "      <td>totalimage</td>\n",
       "      <td>1</td>\n",
       "      <td>body</td>\n",
       "      <td>0</td>\n",
       "      <td>aortavois_ml-2_width-5_aorta_descending_lower</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>124872000</td>\n",
       "      <td>560940.633000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347985</th>\n",
       "      <td>sub-048</td>\n",
       "      <td>totalimage</td>\n",
       "      <td>1</td>\n",
       "      <td>body</td>\n",
       "      <td>0</td>\n",
       "      <td>aortavois_ml-2_width-5_aorta_descending_lower</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>124872000</td>\n",
       "      <td>560940.633000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347986</th>\n",
       "      <td>sub-048</td>\n",
       "      <td>totalimage</td>\n",
       "      <td>1</td>\n",
       "      <td>body</td>\n",
       "      <td>0</td>\n",
       "      <td>aortavois_ml-2_width-5_aorta_descending_lower</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>124872000</td>\n",
       "      <td>560940.633000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347987</th>\n",
       "      <td>sub-048</td>\n",
       "      <td>totalimage</td>\n",
       "      <td>1</td>\n",
       "      <td>body</td>\n",
       "      <td>0</td>\n",
       "      <td>aortavois_ml-2_width-5_aorta_descending_lower</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>124872000</td>\n",
       "      <td>560940.633000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3347988 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subject        Task Label Index Label Name  Erosion Iterations  \\\n",
       "0        sub-072    ts_total           1     spleen                   0   \n",
       "1        sub-072    ts_total           1     spleen                   0   \n",
       "2        sub-072    ts_total           1     spleen                   0   \n",
       "3        sub-072    ts_total           1     spleen                   0   \n",
       "4        sub-072    ts_total           1     spleen                   0   \n",
       "...          ...         ...         ...        ...                 ...   \n",
       "3347983  sub-048  totalimage           1       body                   0   \n",
       "3347984  sub-048  totalimage           1       body                   0   \n",
       "3347985  sub-048  totalimage           1       body                   0   \n",
       "3347986  sub-048  totalimage           1       body                   0   \n",
       "3347987  sub-048  totalimage           1       body                   0   \n",
       "\n",
       "                             Input Function Identifier  Regression Frames  \\\n",
       "0            aortavois_ml-full_width-3_aorta_ascending                  2   \n",
       "1            aortavois_ml-full_width-3_aorta_ascending                  3   \n",
       "2            aortavois_ml-full_width-3_aorta_ascending                  4   \n",
       "3            aortavois_ml-full_width-3_aorta_ascending                  5   \n",
       "4            aortavois_ml-full_width-3_aorta_ascending                  6   \n",
       "...                                                ...                ...   \n",
       "3347983  aortavois_ml-2_width-5_aorta_descending_lower                  4   \n",
       "3347984  aortavois_ml-2_width-5_aorta_descending_lower                  5   \n",
       "3347985  aortavois_ml-2_width-5_aorta_descending_lower                  6   \n",
       "3347986  aortavois_ml-2_width-5_aorta_descending_lower                  7   \n",
       "3347987  aortavois_ml-2_width-5_aorta_descending_lower                  8   \n",
       "\n",
       "         Patlak Ki  Voxel Count    Volume [mL]  \n",
       "0        -0.001252        44072     197.976933  \n",
       "1         0.007039        44072     197.976933  \n",
       "2         0.004963        44072     197.976933  \n",
       "3         0.005037        44072     197.976933  \n",
       "4         0.004364        44072     197.976933  \n",
       "...            ...          ...            ...  \n",
       "3347983   0.000745    124872000  560940.633000  \n",
       "3347984   0.000623    124872000  560940.633000  \n",
       "3347985   0.000621    124872000  560940.633000  \n",
       "3347986   0.000647    124872000  560940.633000  \n",
       "3347987   0.000621    124872000  560940.633000  \n",
       "\n",
       "[3347988 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hedyPET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
