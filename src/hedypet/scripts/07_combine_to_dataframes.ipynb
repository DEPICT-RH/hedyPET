{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f16cd06",
   "metadata": {},
   "source": [
    "## Means, TACS, and metadata\n",
    "Notebook used to create the following pickle data files with readouts from the combined hedyPET train+validation set (n=80):\n",
    " - `readouts/metadata.csv` Participant metadata (weight, demographic-group, and more)- `readouts/acdynPSF_tacs_80.pkl.gz` PET TACs for all segmented regions\n",
    " - `readouts/acstatPSF_mean_80.pkl.gz` PET static means for all segmented regions\n",
    " - `readouts/patlak_ki_80.pkl.gz` Patlak Ki values for all segmented regions for different input functions (IFs) and number off rames\n",
    "\n",
    "Extensive metadata and original image files available at X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da236a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hedypet.utils import STATIC_ROOT, load_splits, get_time_frames_midpoint, DYNAMIC_ROOT\n",
    "from hedypet.utils import get_participant_metadata, get_norm_consts\n",
    "from nifti_dynamic.tacs import load_tac\n",
    "from nifti_dynamic.patlak import roi_patlak\n",
    "from parse import parse\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import os \n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb9853",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ddda7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tsv(file_path):\n",
    "    df = pd.read_csv(file_path,sep=\"\\t\")\n",
    "    return {k:v for k,v in zip(list(df[\"index\"]),list(df.name))}\n",
    "\n",
    "region_names = {\n",
    "    'ts_total' :load_tsv(next((STATIC_ROOT / \"derivatives/totalsegmentator\").glob(\"**/*total*.tsv\"))),\n",
    "    'ts_body' : load_tsv(next((STATIC_ROOT / \"derivatives/totalsegmentator\").glob(\"**/*body*.tsv\"))),\n",
    "    'ts_tissue' :load_tsv(next((STATIC_ROOT / \"derivatives/totalsegmentator\").glob(\"**/*tissue*.tsv\"))),\n",
    "    'synthsegparc' : load_tsv(next((STATIC_ROOT / \"derivatives/synthseg\").glob(\"**/*synthseg*.tsv\"))),\n",
    "    'synthseg' : load_tsv(next((STATIC_ROOT / \"derivatives/synthseg\").glob(\"**/*synthseg*.tsv\"))),\n",
    "    'totalimage' : {1:\"body\"},\n",
    "}\n",
    "\n",
    "region_names_aorta = {1:\"aorta_ascending\",\n",
    "2:\"aorta_top\",\n",
    "3:\"aorta_descending_upper\",\n",
    "4:\"aorta_descending_lower\"}\n",
    "\n",
    "def task_and_ix_to_region_name(task,ix):\n",
    "    ix = int(ix)\n",
    "    if task.startswith(\"aorta\"):\n",
    "        return region_names_aorta[ix]\n",
    "    else:\n",
    "        return region_names[task][ix]\n",
    "\n",
    "subs = load_splits()[\"train0\"]+load_splits()[\"val0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59484cdf",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "Extraction of metadata for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "785ec4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========[Metadata Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Weight [kg]', 'Demographic Group [Sex,Age]', 'suv_const', 'sul_janma_const', 'sul_james_const', 'Injected Activity [MBq]', 'SUV Denominator [Bq/mL]', 'SUL Decazes Denominator [Bq/mL]', 'SUL Janma Denominator [Bq/mL]', 'SUL James Denominator [Bq/mL]']\n",
      "\n",
      "Subjects: 80\n",
      "\n",
      "Demographic Group [Sex,Age]\n",
      "F18-34    10\n",
      "F35-49    10\n",
      "F50-69    10\n",
      "F70-99    10\n",
      "M18-34    10\n",
      "M35-49    10\n",
      "M50-69    10\n",
      "M70-99    10\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(df_path := \"../../../readouts/metadata_80.csv\"):\n",
    "    data = []\n",
    "    for sub in load_splits()[\"train0\"]+load_splits()[\"val0\"]:\n",
    "        x = get_participant_metadata(sub)\n",
    "        x[\"SUV Denominator [Bq/mL]\"] = get_norm_consts(sub)[\"suv\"]\n",
    "        x[\"SUL Decazes Denominator [Bq/mL]\"] = get_norm_consts(sub)[\"sul_decazes\"]\n",
    "        x[\"SUL Janma Denominator [Bq/mL]\"] = get_norm_consts(sub)[\"sul_janma\"]\n",
    "        x[\"SUL James Denominator [Bq/mL]\"] = get_norm_consts(sub)[\"sul_james\"]\n",
    "        data.append(x)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.rename({\"InjectedRadioactivity\":\"Injected Activity [MBq]\",\"participant_id\":\"Subject\",\"weight\":\"Weight [kg]\",\"demographic-group\":\"Demographic Group [Sex,Age]\"},axis=1)\n",
    "    df = df.drop([\"age\",\"height\",\"sex\",\"blanket\"],axis=1)\n",
    "    df.to_csv(df_path,index=False)\n",
    "else:\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "print(\"=\"*10 + \"[Metadata Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Subjects:\", df[\"Subject\"].nunique(),end=\"\\n\\n\")\n",
    "print(df[\"Demographic Group [Sex,Age]\"].value_counts(),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cfd916",
   "metadata": {},
   "source": [
    "## Time Activity Curves\n",
    "Combines the time activity curves from the acdynPSF dynamic PET into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28d952bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========[Time Activity Curves Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Task', 'Label Index', 'Label Name', 'Erosion Iterations', 'Frame Index', 'Frame Time Middle [s]', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count', 'Volume [mL]']\n",
      "\n",
      "Segmentation tasks: ['ts_total', 'synthseg', 'synthsegparc', 'ts_tissue', 'ts_body', 'aortasegments', 'aortavois_ml-full_width-3', 'aortavois_ml-1_width-3', 'aortavois_ml-2_width-5', 'totalimage']\n",
      "\n",
      "N Unique regions: 227\n",
      "\n",
      "Unique erosions: [0 1]\n",
      "\n",
      "Rows: 2860533\n",
      "\n",
      "\n",
      "==========[Input Functions Time Activity Curves Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Task', 'Label Index', 'Label Name', 'Erosion Iterations', 'Frame Index', 'Frame Time Middle [s]', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count', 'Volume [mL]']\n",
      "\n",
      "Segmentation tasks: ['aortavois_ml-full_width-3', 'aortavois_ml-1_width-3', 'aortavois_ml-2_width-5']\n",
      "\n",
      "N Unique regions: 4\n",
      "\n",
      "Unique erosions: [0]\n",
      "\n",
      "Rows: 66240\n"
     ]
    }
   ],
   "source": [
    "df_path = \"../../../readouts/tacs_80.pkl.gz\"\n",
    "df_path_input_function = \"../../../readouts/input_function_tacs_80.pkl.gz\"\n",
    "\n",
    "if not os.path.exists(df_path) or not os.path.exists(df_path_input_function):\n",
    "    data = []\n",
    "    \n",
    "    for sub in tqdm(subs):\n",
    "        tacs_root = (DYNAMIC_ROOT / f\"derivatives/tacs/{sub}/acdynPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "        \n",
    "        # Load the TAC for each ROI with/without erosion\n",
    "        for tac_roi_path in tacs:\n",
    "            frame_time_start, frame_time_end, mu_organ, std_organ, n_organ = load_tac(tac_roi_path)\n",
    "            frame_time_middle = (frame_time_start+frame_time_end) / 2\n",
    "            # Save data to dataframe\n",
    "            frame_ixs = list(range(len(mu_organ)))            \n",
    "            tags = parse('{}/tacs/{sub}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}.csv',str(tac_roi_path)).named\n",
    "            vals = {\"PET Mean [Bq/mL]\":mu_organ,\"PET STD [Bq/mL]\":std_organ,\"Voxel Count\":n_organ,\"Frame Index\":frame_ixs, \"Frame Time Middle [s]\":frame_time_middle}\n",
    "            vals.update(tags)\n",
    "            vals[\"Label Name\"] = task_and_ix_to_region_name(vals[\"task\"],vals[\"ix\"])\n",
    "            data.append(pd.DataFrame(vals))\n",
    "\n",
    "    # Rename and save \n",
    "    df = pd.concat(data)\n",
    "    df = df.rename({\"sub\":\"Subject\",\"task\":\"Task\",\"ix\":\"Label Index\",\"erosion\":\"Erosion Iterations\"},axis=\"columns\")\n",
    "    df[\"Volume [mL]\"] = df[\"Voxel Count\"]*(1.65*1.65* 1.65) / 1000\n",
    "    df[\"Erosion Iterations\"] = df[\"Erosion Iterations\"].astype(int)\n",
    "    df = df[['Subject', 'Task','Label Index', 'Label Name', 'Erosion Iterations', 'Frame Index', 'Frame Time Middle [s]', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count',  'Volume [mL]']]\n",
    "    \n",
    "    df_input_functions = df[df.Task.str.startswith(\"aortavois\")]\n",
    "    df_organs = df[~df.Task.str.startswith(\"aortavois\")]\n",
    "    df_input_functions.to_pickle(df_path_input_function)\n",
    "    df_organs.to_pickle(df_path)\n",
    "else:\n",
    "    df_input_functions = pd.read_pickle(df_path_input_function)\n",
    "    df_organs = pd.read_pickle(df_path)\n",
    "\n",
    "print(\"=\"*10 + \"[Time Activity Curves Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df[\"Task\"].unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"Label Name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df[\"Erosion Iterations\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df),end=\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\"*10 + \"[Input Functions Time Activity Curves Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df_input_functions.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df_input_functions[\"Task\"].unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df_input_functions[\"Label Name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df_input_functions[\"Erosion Iterations\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df_input_functions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cda002",
   "metadata": {},
   "source": [
    "## Static Organ Means\n",
    "Combines the static organ means from the acstatPSF reconstruction into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "115e5dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [02:04<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========[Means Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Task', 'Label Index', 'Label Name', 'Erosion Iterations', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count', 'Volume [mL]']\n",
      "\n",
      "Segmentation tasks: ['ts_total', 'synthseg', 'synthsegparc', 'ts_tissue', 'ts_body', 'totalimage']\n",
      "\n",
      "N Unique regions: 223\n",
      "\n",
      "Unique erosions: [0 1]\n",
      "\n",
      "Rows: 39809\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(df_path := \"../../../readouts/means_80.pkl.gz\"):\n",
    "    data = []\n",
    "    \n",
    "    for sub in tqdm(subs):\n",
    "        tacs_root = (STATIC_ROOT / f\"derivatives/tacs/{sub}/acstatPSF\")\n",
    "\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "                \n",
    "        # Load the ROI means for all regions (with/without eerosion)\n",
    "        for tac_roi_path in tacs:\n",
    "            _,_,mu_organ, std_organ, n_organ = load_tac(tac_roi_path)\n",
    "\n",
    "            # Save data to dataframe\n",
    "            tags = parse('{}/tacs/{sub}/acstatPSF/{task}/erosion-{erosion}/tac_{ix}.csv',str(tac_roi_path)).named\n",
    "            vals = {\"PET Mean [Bq/mL]\":float(mu_organ.item()),\"PET STD [Bq/mL]\":float(std_organ.item()),\"Voxel Count\":int(n_organ.item())}\n",
    "            vals.update(tags)\n",
    "            vals[\"Label Name\"] = task_and_ix_to_region_name(vals[\"task\"],vals[\"ix\"])\n",
    "            data.append(vals)\n",
    "\n",
    "    # Rename and save \n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.rename({\"sub\":\"Subject\",\"task\":\"Task\",\"ix\":\"Label Index\",\"erosion\":\"Erosion Iterations\"},axis=\"columns\")\n",
    "    df[\"Volume [mL]\"] = df[\"Voxel Count\"]*(1.65*1.65* 2.0) / 1000\n",
    "    df[\"Erosion Iterations\"] = df[\"Erosion Iterations\"].astype(int)\n",
    "    df = df[['Subject', 'Task','Label Index', 'Label Name', 'Erosion Iterations', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count', 'Volume [mL]']]\n",
    "    df.to_pickle(df_path)\n",
    "    \n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n",
    "\n",
    "print(\"=\"*10 + \"[Means Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df[\"Task\"].unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"Label Name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df[\"Erosion Iterations\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba510e8",
   "metadata": {},
   "source": [
    "## Patlak\n",
    "\n",
    "Computes and saves the Patlak Ki for different organ and input-function combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6177766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/80 [00:27<36:49, 27.97s/it]"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not os.path.exists(df_path := \"../../../readouts/patlak_ki_80.pkl.gz\"):\n",
    "\n",
    "    #Number of last frames to perform Patlak regression on\n",
    "    frames = [2,3,4,5,6,7,8]\n",
    "    ki_data = []\n",
    "\n",
    "    for sub in tqdm(subs):\n",
    "\n",
    "        #Find all TACs (organs, input functions, and with/without erosion)\n",
    "        tacs_root = (DYNAMIC_ROOT / f\"derivatives/tacs/{sub}/acdynPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "\n",
    "        #Divide into input function TACs and ROI tacs\n",
    "        tacs_if = [x for x in tacs if \"aortavois\" in str(x)]\n",
    "        tacs_roi = [x for x in tacs if \"aorta\" not in str(x)]\n",
    "        \n",
    "        # For each input function\n",
    "        for tac_if_path in tacs_if:\n",
    "            frame_time_start, frame_time_end,tac_if, _, _ = load_tac(tac_if_path)\n",
    "            t_middle = (frame_time_start+frame_time_end) / 2\n",
    "            # For each organ\n",
    "            for tac_roi_path in tacs_roi:\n",
    "                _,_, tac_organ, _, n = load_tac(tac_roi_path)\n",
    "            \n",
    "                # For different number of regression Frames\n",
    "                for frame in frames:\n",
    "\n",
    "                    # Run Patlak analysis\n",
    "                    slope, intercept, X, Y = roi_patlak(tac_organ,tac_if,t_middle,frame)\n",
    "\n",
    "                    # And parse the data for the dataframe\n",
    "                    tags_if = parse('{}/tacs/{}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}.csv',str(tac_if_path)).named\n",
    "                    tags_organ = parse('{}/tacs/{sub}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}.csv',str(tac_roi_path)).named\n",
    "                    if_tag = tags_if[\"task\"]+\"_\"+task_and_ix_to_region_name(tags_if[\"task\"], tags_if[\"ix\"])\n",
    "                    series = {\"Patlak Ki\":float(slope),\"Voxel Count\":int(n[0]),\"Regression Frames\":frame}\n",
    "                    series[\"Input Function Identifier\"] = if_tag\n",
    "                    series.update(tags_organ)\n",
    "                    series[\"Label Name\"] = task_and_ix_to_region_name(series[\"task\"], series[\"ix\"])\n",
    "                    \n",
    "                    ki_data.append(series)\n",
    "                    \n",
    "    # Rename and save \n",
    "    df = pd.DataFrame(ki_data)\n",
    "    df = df.rename({\"sub\":\"Subject\",\"task\":\"Task\",\"ix\":\"Label Index\",\"erosion\":\"Erosion Iterations\"},axis=\"columns\")\n",
    "    df[\"Volume [mL]\"] = df[\"Voxel Count\"]*(1.65*1.65* 1.65) / 1000\n",
    "    df[\"Erosion Iterations\"] = df[\"Erosion Iterations\"].astype(int)\n",
    "    df = df[['Subject','Task',  'Label Index', 'Label Name', 'Erosion Iterations', 'Input Function Identifier', 'Regression Frames', 'Patlak Ki', 'Voxel Count', 'Volume [mL]']]\n",
    "    df.to_pickle(df_path)\n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n",
    "\n",
    "print(\"=\"*10 + \"[Patlak Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df[\"Task\"].unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"Label Name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df[\"Erosion Iterations\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Unique patlak frames:\", df[\"Regression Frames\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Unique input functions\" , df[\"Input Function Identifier\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hedyPET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
