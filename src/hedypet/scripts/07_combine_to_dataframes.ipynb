{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f16cd06",
   "metadata": {},
   "source": [
    "## Means, TACS, and metadata\n",
    "Notebook used to create the following pickle data files with readouts from the combined hedyPET train+validation set (n=80):\n",
    " - `readouts/metadata.csv` Participant metadata (weight, demographic-group, and more)- `readouts/acdynPSF_tacs_80.pkl.gz` PET TACs for all segmented regions\n",
    " - `readouts/acstatPSF_mean_80.pkl.gz` PET static means for all segmented regions\n",
    " - `readouts/patlak_ki_80.pkl.gz` Patlak Ki values for all segmented regions for different input functions (IFs) and number off rames\n",
    "\n",
    "Extensive metadata and original image files available at X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da236a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hedypet.utils import DERIVATIVES_ROOT, load_splits, get_time_frames_midpoint\n",
    "from hedypet.utils import get_participant_metadata, get_norm_consts\n",
    "from nifti_dynamic.utils import load_tac\n",
    "from nifti_dynamic.patlak import roi_patlak\n",
    "from parse import parse\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import os \n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb9853",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ddda7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    with open(file_path,\"r\") as handle:\n",
    "        d = json.load(handle)\n",
    "    return d\n",
    "\n",
    "region_names = {\n",
    "    'ts_total' :load_json(DERIVATIVES_ROOT / \"tacs/ts_total_classes.json\"),\n",
    "    'synthseg' :load_json(DERIVATIVES_ROOT / \"tacs/synthseg_classes.json\"),\n",
    "    'synthsegparc' : load_json(DERIVATIVES_ROOT / \"tacs/synthseg_classes.json\"),\n",
    "    'ts_tissue' :load_json(DERIVATIVES_ROOT / \"tacs/ts_tissue_classes.json\"),\n",
    "    'ts_body' : load_json(DERIVATIVES_ROOT / \"tacs/ts_body_classes.json\"),\n",
    "    'totalimage' : {\"1\":\"body\"},\n",
    "}\n",
    "region_names_aorta = load_json(DERIVATIVES_ROOT / \"tacs/aorta_classes.json\")\n",
    "\n",
    "def task_and_ix_to_region_name(task,ix):\n",
    "    if task.startswith(\"aorta\"):\n",
    "        return region_names_aorta[ix]\n",
    "    else:\n",
    "        return region_names[task][ix]\n",
    "\n",
    "subs = load_splits()[\"train0\"]+load_splits()[\"val0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59484cdf",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "Extraction of metadata for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "785ec4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['participant', 'weight', 'demographic-group', 'injected_readioactivity', 'suv_denominator']\n",
      "Subjects: 80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "demographic-group\n",
       "F18-34    10\n",
       "F35-49    10\n",
       "F50-69    10\n",
       "F70-99    10\n",
       "M18-34    10\n",
       "M35-49    10\n",
       "M50-69    10\n",
       "M70-99    10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(df_path := \"../../../readouts/metadata.csv\"):\n",
    "    data = []\n",
    "    for sub in load_splits()[\"train0\"]+load_splits()[\"val0\"]:\n",
    "        x = get_participant_metadata(sub)\n",
    "        x[\"suv_denominator\"] = get_norm_consts(sub)[\"suv\"]\n",
    "        data.append(x)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.rename({\"InjectedRadioactivity\":\"injected_readioactivity\",\"participant_id\":\"participant\"},axis=1)\n",
    "    df = df.drop([\"age\",\"height\",\"sex\",\"blanket\"],axis=1)\n",
    "    df.to_csv(df_path,index=False)\n",
    "else:\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(\"Subjects:\", df[\"participant\"].nunique())\n",
    "df[\"demographic-group\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cfd916",
   "metadata": {},
   "source": [
    "## Time Activity Curves\n",
    "Combines the time activity curves from the acdynPSF dynamic PET into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28d952bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['pet_mu', 'pet_std', 'n_voxels', 'frame_ix', 'frame_time_middle', 'participant', 'seg_task', 'erosion_iterations', 'seg_region_ix', 'seg_region_name', 'mL']\n",
      "\n",
      "Segmentation tasks: ['ts_total', 'ts_tissue', 'ts_body', 'synthseg', 'synthsegparc', 'aortasegments', 'aortavois_ml-1_width-3', 'aortavois_ml-1.5_width-5', 'aortavois_ml-2_width-5', 'totalimage']\n",
      "\n",
      "N Unique regions: 227\n",
      "\n",
      "Unique erosions: [0 1]\n",
      "\n",
      "Rows: 2859981\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists(df_path := \"../../../readouts/acdynPSF_tacs_80.pkl.gz\"):\n",
    "    data = []\n",
    "    \n",
    "    for sub in tqdm(subs):\n",
    "        tacs_root = (DERIVATIVES_ROOT / f\"tacs/{sub}/acdynPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "        frame_time_middle = get_time_frames_midpoint(sub)\n",
    "                \n",
    "        for tac_organ_path in tacs:\n",
    "            mu_organ, std_organ, n_organ = load_tac(tac_organ_path)\n",
    "            frame_ixs = list(range(len(mu_organ)))\n",
    "\n",
    "            assert len(frame_ixs) == len(frame_time_middle)\n",
    "            \n",
    "            tags = parse('{}/tacs/{sub}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_organ_path)).named\n",
    "            vals = {\"pet_mu\":mu_organ,\"pet_std\":std_organ,\"n_voxels\":n_organ,\"frame_ix\":frame_ixs, \"frame_time_middle\":frame_time_middle}\n",
    "            vals.update(tags)\n",
    "            vals[\"seg_region_name\"] = task_and_ix_to_region_name(vals[\"task\"],vals[\"ix\"])\n",
    "            data.append(pd.DataFrame(vals))\n",
    "\n",
    "    df = pd.concat(data)\n",
    "    df = df.rename({\"sub\":\"participant\",\"task\":\"seg_task\",\"ix\":\"seg_region_ix\",\"erosion\":\"erosion_iterations\"},axis=\"columns\")\n",
    "    df[\"mL\"] = df.n_voxels*(1.65*1.65* 1.65) / 1000\n",
    "    df.erosion_iterations = df.erosion_iterations.astype(int)\n",
    "    df.to_pickle(df_path)\n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n",
    "\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df.seg_task.unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"seg_region_name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df.erosion_iterations.unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cda002",
   "metadata": {},
   "source": [
    "## Static Organ Means\n",
    "Combines the static organ means from the acstatPSF reconstruction into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e5dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['pet_mu', 'pet_std', 'n_voxels', 'participant', 'seg_task', 'erosion_iterations', 'seg_region_ix', 'seg_region_name', 'mL']\n",
      "\n",
      "Segmentation tasks: ['ts_total', 'synthseg', 'synthsegparc', 'ts_tissue', 'ts_body', 'totalimage']\n",
      "\n",
      "N Unique regions: 223\n",
      "\n",
      "Unique erosions: [0 1]\n",
      "\n",
      "Rows: 39801\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(df_path := \"../../../readouts/acstatPSF_means_80.pkl.gz\"):\n",
    "    data = []\n",
    "    \n",
    "    for sub in tqdm(subs):\n",
    "        tacs_root = (DERIVATIVES_ROOT / f\"tacs/{sub}/acstatPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "                \n",
    "        # Try all combinations of inputs functions and num_frames\n",
    "        for tac_organ_path in tacs:\n",
    "            mu_organ, std_organ, n_organ = load_tac(tac_organ_path)\n",
    "            tags = parse('{}/tacs/{sub}/acstatPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_organ_path)).named\n",
    "            vals = {\"pet_mu\":float(mu_organ),\"pet_std\":float(std_organ),\"n_voxels\":int(n_organ)}\n",
    "            vals.update(tags)\n",
    "            vals[\"seg_region_name\"] = task_and_ix_to_region_name(vals[\"task\"],vals[\"ix\"])\n",
    "            data.append(vals)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.rename({\"sub\":\"participant\",\"task\":\"seg_task\",\"ix\":\"seg_region_ix\",\"erosion\":\"erosion_iterations\"},axis=\"columns\")\n",
    "    df[\"mL\"] = df.n_voxels*(1.65*1.65* 2.0) / 1000\n",
    "    df.erosion_iterations = df.erosion_iterations.astype(int)\n",
    "    df.to_pickle(df_path)\n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n",
    "\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df.seg_task.unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"seg_region_name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df.erosion_iterations.unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba510e8",
   "metadata": {},
   "source": [
    "## Patlak\n",
    "\n",
    "Computes and saves the Patlak Ki for different organ and input-function combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6177766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['Ki', 'n_voxels', 'n_frames_regression', 'if_tag', 'participant', 'seg_task', 'erosion_iterations', 'seg_region_ix', 'seg_region_name', 'mL']\n",
      "\n",
      "Segmentation tasks: ['ts_total', 'ts_tissue', 'ts_body', 'synthseg', 'synthsegparc', 'totalimage']\n",
      "\n",
      "N Unique regions: 223\n",
      "\n",
      "Unique erosions: [0 1]\n",
      "\n",
      "Unique patlak frames: [2 3 4 5 6 7 8]\n",
      "\n",
      "Unique input functions ['aortavois_ml-1_width-3_aorta_ascending'\n",
      " 'aortavois_ml-1_width-3_aorta_top'\n",
      " 'aortavois_ml-1_width-3_aorta_descending_upper'\n",
      " 'aortavois_ml-1_width-3_aorta_descending_lower'\n",
      " 'aortavois_ml-1.5_width-5_aorta_ascending'\n",
      " 'aortavois_ml-1.5_width-5_aorta_top'\n",
      " 'aortavois_ml-1.5_width-5_aorta_descending_upper'\n",
      " 'aortavois_ml-1.5_width-5_aorta_descending_lower'\n",
      " 'aortavois_ml-2_width-5_aorta_ascending'\n",
      " 'aortavois_ml-2_width-5_aorta_top'\n",
      " 'aortavois_ml-2_width-5_aorta_descending_upper'\n",
      " 'aortavois_ml-2_width-5_aorta_descending_lower']\n",
      "\n",
      "Rows: 3347316\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not os.path.exists(df_path := \"../../../readouts/patlak_ki_80.pkl.gz\"):\n",
    "\n",
    "    frames = [2,3,4,5,6,7,8]\n",
    "    ki_data = []\n",
    "\n",
    "    for sub in tqdm(subs):\n",
    "        #Find all tacs\n",
    "        tacs_root = (DERIVATIVES_ROOT / f\"tacs/{sub}/acdynPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "\n",
    "        tacs_if = [x for x in tacs if \"aortavois\" in str(x)]\n",
    "        tacs_organs = [x for x in tacs if \"aorta\" not in str(x)]\n",
    "        \n",
    "        t_middle = get_time_frames_midpoint(sub)\n",
    "\n",
    "        # Try all combinations of inputs functions and num_frames\n",
    "        for tac_if_path in tacs_if:\n",
    "            tac_if, _, _ = load_tac(tac_if_path)\n",
    "            for tac_organ_path in tacs_organs:\n",
    "                tac_organ, _, n = load_tac(tac_organ_path)\n",
    "                for frame in frames:\n",
    "                    slope, intercept, X, Y = roi_patlak(tac_organ,tac_if,t_middle,frame)\n",
    "\n",
    "                    tags_if = parse('{}/tacs/{}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_if_path)).named\n",
    "                    tags_organ = parse('{}/tacs/{sub}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_organ_path)).named\n",
    "                    \n",
    "                    if_tag = tags_if[\"task\"]+\"_\"+task_and_ix_to_region_name(tags_if[\"task\"], tags_if[\"ix\"])\n",
    "                    \n",
    "                    series = {\"Ki\":float(slope),\"n_voxels\":int(n[0]),\"n_frames_regression\":frame}\n",
    "                    series[\"if_tag\"] = if_tag\n",
    "                    series.update(tags_organ)\n",
    "                    series[\"seg_region_name\"] = task_and_ix_to_region_name(series[\"task\"], series[\"ix\"])\n",
    "                    ki_data.append(series)\n",
    "                    \n",
    "    df = pd.DataFrame(ki_data)\n",
    "    df = df.rename({\"sub\":\"participant\",\"task\":\"seg_task\",\"ix\":\"seg_region_ix\",\"erosion\":\"erosion_iterations\"},axis=\"columns\")\n",
    "    df[\"mL\"] = df.n_voxels*(1.65*1.65* 1.65) / 1000\n",
    "    df.erosion_iterations = df.erosion_iterations.astype(int)\n",
    "    df.to_pickle(df_path)\n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n",
    "\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df.seg_task.unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"seg_region_name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df.erosion_iterations.unique(),end=\"\\n\\n\")\n",
    "print(\"Unique patlak frames:\", df.n_frames_regression.unique(),end=\"\\n\\n\")\n",
    "print(\"Unique input functions\" , df.if_tag.unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hedyPET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
