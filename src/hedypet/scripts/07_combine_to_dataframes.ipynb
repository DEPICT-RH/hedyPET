{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f16cd06",
   "metadata": {},
   "source": [
    "## Means, TACS, and metadata\n",
    "Notebook used to create the following pickle data files with readouts from the combined hedyPET train+validation set (n=80):\n",
    " - `readouts/metadata.csv` Participant metadata (weight, demographic-group, and more)- `readouts/acdynPSF_tacs_80.pkl.gz` PET TACs for all segmented regions\n",
    " - `readouts/acstatPSF_mean_80.pkl.gz` PET static means for all segmented regions\n",
    " - `readouts/patlak_ki_80.pkl.gz` Patlak Ki values for all segmented regions for different input functions (IFs) and number off rames\n",
    "\n",
    "Extensive metadata and original image files available at X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da236a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hedypet.utils import DERIVATIVES_ROOT, load_splits, get_time_frames_midpoint\n",
    "from hedypet.utils import get_participant_metadata, get_norm_consts\n",
    "from nifti_dynamic.utils import load_tac\n",
    "from nifti_dynamic.patlak import roi_patlak\n",
    "from parse import parse\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import os \n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb9853",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ddda7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    with open(file_path,\"r\") as handle:\n",
    "        d = json.load(handle)\n",
    "    return d\n",
    "\n",
    "region_names = {\n",
    "    'ts_total' :load_json(DERIVATIVES_ROOT / \"tacs/ts_total_classes.json\"),\n",
    "    'synthseg' :load_json(DERIVATIVES_ROOT / \"tacs/synthseg_classes.json\"),\n",
    "    'synthsegparc' : load_json(DERIVATIVES_ROOT / \"tacs/synthseg_classes.json\"),\n",
    "    'ts_tissue' :load_json(DERIVATIVES_ROOT / \"tacs/ts_tissue_classes.json\"),\n",
    "    'ts_body' : load_json(DERIVATIVES_ROOT / \"tacs/ts_body_classes.json\"),\n",
    "    'totalimage' : {\"1\":\"body\"},\n",
    "}\n",
    "region_names_aorta = load_json(DERIVATIVES_ROOT / \"tacs/aorta_classes.json\")\n",
    "\n",
    "def task_and_ix_to_region_name(task,ix):\n",
    "    if task.startswith(\"aorta\"):\n",
    "        return region_names_aorta[ix]\n",
    "    else:\n",
    "        return region_names[task][ix]\n",
    "\n",
    "subs = load_splits()[\"train0\"]+load_splits()[\"val0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59484cdf",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "Extraction of metadata for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ec4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========[Metadata Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Weight [kg]', 'Demographic Group [Sex,Age]', 'Injected Activity [MBq]', 'SUV Denominator [Bq/mL]']\n",
      "\n",
      "Subjects: 80\n",
      "\n",
      "Demographic Group [Sex,Age]\n",
      "F18-34    10\n",
      "F35-49    10\n",
      "F50-69    10\n",
      "F70-99    10\n",
      "M18-34    10\n",
      "M35-49    10\n",
      "M50-69    10\n",
      "M70-99    10\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(df_path := \"../../../readouts/metadata_80.csv\"):\n",
    "    data = []\n",
    "    for sub in load_splits()[\"train0\"]+load_splits()[\"val0\"]:\n",
    "        x = get_participant_metadata(sub)\n",
    "        x[\"SUV Denominator [Bq/mL]\"] = get_norm_consts(sub)[\"suv\"]\n",
    "        data.append(x)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.rename({\"InjectedRadioactivity\":\"Injected Activity [MBq]\",\"participant_id\":\"Subject\",\"weight\":\"Weight [kg]\",\"demographic-group\":\"Demographic Group [Sex,Age]\"},axis=1)\n",
    "    df = df.drop([\"age\",\"height\",\"sex\",\"blanket\"],axis=1)\n",
    "    df.to_csv(df_path,index=False)\n",
    "else:\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "print(\"=\"*10 + \"[Metadata Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Subjects:\", df[\"Subject\"].nunique(),end=\"\\n\\n\")\n",
    "print(df[\"Demographic Group [Sex,Age]\"].value_counts(),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cfd916",
   "metadata": {},
   "source": [
    "## Time Activity Curves\n",
    "Combines the time activity curves from the acdynPSF dynamic PET into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d952bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [03:53<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========[Time Activity Curves Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Task', 'Label Index', 'Label Name', 'Erosion Iterations', 'Frame Index', 'Frame Time Middle [s]', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count', 'Volume [mL]']\n",
      "\n",
      "Segmentation tasks: ['ts_total', 'ts_tissue', 'ts_body', 'synthseg', 'synthsegparc', 'aortasegments', 'aortavois_ml-1_width-3', 'aortavois_ml-1.5_width-5', 'aortavois_ml-2_width-5', 'totalimage']\n",
      "\n",
      "N Unique regions: 227\n",
      "\n",
      "Unique erosions: [0 1]\n",
      "\n",
      "Rows: 2859981\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(df_path := \"../../../readouts/tacs_80.pkl.gz\"):\n",
    "    data = []\n",
    "    \n",
    "    for sub in tqdm(subs):\n",
    "        tacs_root = (DERIVATIVES_ROOT / f\"tacs/{sub}/acdynPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "        frame_time_middle = get_time_frames_midpoint(sub)\n",
    "        \n",
    "        # Load the TAC for each ROI with/without erosion\n",
    "        for tac_roi_path in tacs:\n",
    "            mu_organ, std_organ, n_organ = load_tac(tac_roi_path)\n",
    "\n",
    "            # Save data to dataframe\n",
    "            frame_ixs = list(range(len(mu_organ)))            \n",
    "            tags = parse('{}/tacs/{sub}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_roi_path)).named\n",
    "            vals = {\"PET Mean [Bq/mL]\":mu_organ,\"PET STD [Bq/mL]\":std_organ,\"Voxel Count\":n_organ,\"Frame Index\":frame_ixs, \"Frame Time Middle [s]\":frame_time_middle}\n",
    "            vals.update(tags)\n",
    "            vals[\"Label Name\"] = task_and_ix_to_region_name(vals[\"task\"],vals[\"ix\"])\n",
    "            data.append(pd.DataFrame(vals))\n",
    "\n",
    "    # Rename and save \n",
    "    df = pd.concat(data)\n",
    "    df = df.rename({\"sub\":\"Subject\",\"task\":\"Task\",\"ix\":\"Label Index\",\"erosion\":\"Erosion Iterations\"},axis=\"columns\")\n",
    "    df[\"Volume [mL]\"] = df[\"Voxel Count\"]*(1.65*1.65* 1.65) / 1000\n",
    "    df[\"Erosion Iterations\"] = df[\"Erosion Iterations\"].astype(int)\n",
    "    df = df[['Subject', 'Task','Label Index', 'Label Name', 'Erosion Iterations', 'Frame Index', 'Frame Time Middle [s]', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count',  'Volume [mL]']]\n",
    "    df.to_pickle(df_path)\n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n",
    "\n",
    "print(\"=\"*10 + \"[Time Activity Curves Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df[\"Task\"].unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"Label Name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df[\"Erosion Iterations\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cda002",
   "metadata": {},
   "source": [
    "## Static Organ Means\n",
    "Combines the static organ means from the acstatPSF reconstruction into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e5dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:46<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========[Means Dataframe]==========\n",
      "\n",
      "Columns: ['Subject', 'Task', 'Label Index', 'Label Name', 'Erosion Iterations', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count', 'Volume [mL]']\n",
      "\n",
      "Segmentation tasks: ['ts_total', 'synthseg', 'synthsegparc', 'ts_tissue', 'ts_body', 'totalimage']\n",
      "\n",
      "N Unique regions: 223\n",
      "\n",
      "Unique erosions: [0 1]\n",
      "\n",
      "Rows: 39801\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(df_path := \"../../../readouts/means_80.pkl.gz\"):\n",
    "    data = []\n",
    "    \n",
    "    for sub in tqdm(subs):\n",
    "        tacs_root = (DERIVATIVES_ROOT / f\"tacs/{sub}/acstatPSF\")\n",
    "\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "                \n",
    "        # Load the ROI means for all regions (with/without eerosion)\n",
    "        for tac_roi_path in tacs:\n",
    "            mu_organ, std_organ, n_organ = load_tac(tac_roi_path)\n",
    "\n",
    "            # Save data to dataframe\n",
    "            tags = parse('{}/tacs/{sub}/acstatPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_roi_path)).named\n",
    "            vals = {\"PET Mean [Bq/mL]\":float(mu_organ.item()),\"PET STD [Bq/mL]\":float(std_organ.item()),\"Voxel Count\":int(n_organ.item())}\n",
    "            vals.update(tags)\n",
    "            vals[\"Label Name\"] = task_and_ix_to_region_name(vals[\"task\"],vals[\"ix\"])\n",
    "            data.append(vals)\n",
    "\n",
    "    # Rename and save \n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.rename({\"sub\":\"Subject\",\"task\":\"Task\",\"ix\":\"Label Index\",\"erosion\":\"Erosion Iterations\"},axis=\"columns\")\n",
    "    df[\"Volume [mL]\"] = df[\"Voxel Count\"]*(1.65*1.65* 2.0) / 1000\n",
    "    df[\"Erosion Iterations\"] = df[\"Erosion Iterations\"].astype(int)\n",
    "    df = df[['Subject', 'Task','Label Index', 'Label Name', 'Erosion Iterations', 'PET Mean [Bq/mL]', 'PET STD [Bq/mL]', 'Voxel Count', 'Volume [mL]']]\n",
    "    df.to_pickle(df_path)\n",
    "    \n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n",
    "\n",
    "print(\"=\"*10 + \"[Means Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df[\"Task\"].unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"Label Name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df[\"Erosion Iterations\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba510e8",
   "metadata": {},
   "source": [
    "## Patlak\n",
    "\n",
    "Computes and saves the Patlak Ki for different organ and input-function combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6177766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 29/80 [15:10<25:46, 30.32s/it]"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not os.path.exists(df_path := \"../../../readouts/patlak_ki_80.pkl.gz\"):\n",
    "\n",
    "    #Number of last frames to perform Patlak regression on\n",
    "    frames = [2,3,4,5,6,7,8]\n",
    "    ki_data = []\n",
    "\n",
    "    for sub in tqdm(subs):\n",
    "\n",
    "        #Find all TACs (organs, input functions, and with/without erosion)\n",
    "        tacs_root = (DERIVATIVES_ROOT / f\"tacs/{sub}/acdynPSF\")\n",
    "        tacs = list(tacs_root.glob(\"**/tac*\"))\n",
    "\n",
    "        #Divide into input function TACs and ROI tacs\n",
    "        tacs_if = [x for x in tacs if \"aortavois\" in str(x)]\n",
    "        tacs_roi = [x for x in tacs if \"aorta\" not in str(x)]\n",
    "        \n",
    "        t_middle = get_time_frames_midpoint(sub)\n",
    "\n",
    "        # For each input function\n",
    "        for tac_if_path in tacs_if:\n",
    "            tac_if, _, _ = load_tac(tac_if_path)\n",
    "            \n",
    "            # For each organ\n",
    "            for tac_roi_path in tacs_roi:\n",
    "                tac_organ, _, n = load_tac(tac_roi_path)\n",
    "\n",
    "                # For different number of regression Frames\n",
    "                for frame in frames:\n",
    "\n",
    "                    # Run Patlak analysis\n",
    "                    slope, intercept, X, Y = roi_patlak(tac_organ,tac_if,t_middle,frame)\n",
    "\n",
    "                    # And parse the data for the dataframe\n",
    "                    tags_if = parse('{}/tacs/{}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_if_path)).named\n",
    "                    tags_organ = parse('{}/tacs/{sub}/acdynPSF/{task}/erosion-{erosion}/tac_{ix}',str(tac_roi_path)).named\n",
    "                    if_tag = tags_if[\"task\"]+\"_\"+task_and_ix_to_region_name(tags_if[\"task\"], tags_if[\"ix\"])\n",
    "                    series = {\"Patlak Ki\":float(slope),\"Voxel Count\":int(n[0]),\"Regression Frames\":frame}\n",
    "                    series[\"Input Function Identifier\"] = if_tag\n",
    "                    series.update(tags_organ)\n",
    "                    series[\"Label Name\"] = task_and_ix_to_region_name(series[\"task\"], series[\"ix\"])\n",
    "                    \n",
    "                    ki_data.append(series)\n",
    "                    \n",
    "    # Rename and save \n",
    "    df = pd.DataFrame(ki_data)\n",
    "    df = df.rename({\"sub\":\"Subject\",\"task\":\"Task\",\"ix\":\"Label Index\",\"erosion\":\"Erosion Iterations\"},axis=\"columns\")\n",
    "    df[\"Volume [mL]\"] = df[\"Voxel Count\"]*(1.65*1.65* 1.65) / 1000\n",
    "    df[\"Erosion Iterations\"] = df[\"Erosion Iterations\"].astype(int)\n",
    "    df = df[['Subject','Task',  'Label Index', 'Label Name', 'Erosion Iterations', 'Input Function Identifier', 'Regression Frames', 'Patlak Ki', 'Voxel Count', 'Volume [mL]']]\n",
    "    df.to_pickle(df_path)\n",
    "else:\n",
    "    df = pd.read_pickle(df_path)\n",
    "\n",
    "\n",
    "print(\"=\"*10 + \"[Patlak Dataframe]\" + \"=\"*10,end=\"\\n\\n\")\n",
    "print(\"Columns:\", list(df.columns),end=\"\\n\\n\")\n",
    "print(\"Segmentation tasks:\", list(df[\"Task\"].unique()),end=\"\\n\\n\")\n",
    "print(\"N Unique regions:\", df[\"Label Name\"].nunique(), end=\"\\n\\n\")\n",
    "print(\"Unique erosions:\", df[\"Erosion Iterations\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Unique patlak frames:\", df[\"Regression Frames\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Unique input functions\" , df[\"Input Function Identifier\"].unique(),end=\"\\n\\n\")\n",
    "print(\"Rows:\",len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
